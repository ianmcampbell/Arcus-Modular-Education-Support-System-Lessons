---
title: "Exact Test of Goodness-of-Fit"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(data.table)
library(dplyr)
library(rcompanion)
knitr::opts_chunk$set(echo = FALSE)

```

## Background

#### Variables

>One [nominal variable](http://www.biostathandbook.com/variabletypes.html#nominal)    

#### Null and Alternative Hypotheses

> H<sub>0</sub> For a [two-tailed test](http://www.biostathandbook.com/hypothesistesting.html#tails), which is what you almost always should use, is that the number of observations in each category is equal to that predicted by a biological theory.    
H<sub>A</sub> is that the observed data are different from the expected.

>H<sub>0</sub> for a one-tailed test is that the observed number for one category is equal to or less than the expected.
h<sub>A</sub> is that the observed number in that category is greater than expected.

For example, if you do a genetic cross in which you expect a 3:1 ratio of green to yellow pea pods, and you have a total of 50 plants, your null hypothesis is that there are 37.5 plants with green pods and 12.5 with yellow pods.

```{r vars, echo=FALSE}
question("You might use an exact test of goodness-of-fit to examine which of the following relationships?",
      answer("Height and weight"),
      answer("Height, weight, and age group"),
      answer("Whether a child uses his right hand more frequently than his left hand", correct = TRUE),
      answer("Height, weight, and season")
)
```

### Why use it? 

The most common use is a nominal variable with only two values (such as male or female, left or right, green or yellow), in which case the test may be called the *exact binomial test*. You compare the observed data with the expected data, which are some kind of theoretical expectation (such as a 1:1 sex ratio or a 3:1 ratio in a genetic cross) that you determined before you collected the data. If the total number of observations is too high, computers may not be able to do the calculations for the exact test, and you should use a [G–test](http://www.biostathandbook.com/gtestgof.html) or [chi-square](http://www.biostathandbook.com/chigof.html)  test of goodness-of-fit instead (and they will give almost exactly the same result).

You can do exact multinomial tests of goodness-of-fit when the nominal variable has more than two values. The basic concepts are the same as for the exact binomial test. Here I'm limiting most of the explanation to the binomial test, because it's more commonly used and easier to understand.


```{r why, echo=FALSE}
question("When might you NOT want to use the exact test of goodness-of-fit despite having a single nominal variable?",
      answer("When you your data is normally distributed"),
      answer("When your data is very large", correct = TRUE),
      answer("When your data is NOT normally distributed"),
      answer("When you have skewed data")
)
```

### Assumptions



```{r rank, echo=FALSE}
question("How do you make ranked data?",
      answer("You rate the data on a scale from poor to excellent"),
      answer("The smallest measurement is 1, the second smallest is 2, and so on through all the values you have", correct = TRUE),
      answer("The largest measurement is 1, the second largest is 2, and so on through all your values"),
      answer("You submit your data for IRB review in a contest to see which researcher has the best data")
)
```



```{r hetero, echo=FALSE}
question("Upon which assumptions does the Kruskal-Wallis test rest?",
      answer("Normality"),
      answer("Inter-related variables"),
      answer("Ranking"),
      answer("Homoscedasticity and same group distributions", correct = TRUE)
)
```



```{r assumptions, echo=FALSE}
question("Upon what assumptions does the Kruskal-Wallis test NOT rely?",
      answer("Normality and homoscedasticity"),
      answer("Wechsler test results"),
      answer("Packages like dplyr and base stats"),
      answer("All of the above", correct = TRUE)
)
```

```{r best, echo=FALSE}
question("What is the BEST situation in which to use a Kruskal-Wallis test?",
      answer("When your data ISN'T normal"),
      answer("When your data is homoscedastic"),
      answer("When your data is actually ranked (a relatively rare occurence)", correct = TRUE),
      answer("When your data is normal but the data set is very small")
)
```


## Practice

#### Load Packages

The following code checks to see if you have the required packages and, if you don't, installs them to your R environment. You can copy and paste this code into your local copy of RStudio or run it from here to see what happens. 

```{r packages, exercise=TRUE, eval = FALSE}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(FSA)){install.packages("FSA")}
if(!require(DescTools)){install.packages("DescTools")}
if(!require(rcompanion)){install.packages("rcompanion")}
if(!require(multcompView)){install.packages("multcompView")}
if(!require(pwr)){install.packages("pwr")}
if(!require(lattice)){install.packages("lattice")}
library(FSA)
library(dplyr)
library(DescTools)
library(rcompanion)
library(multcompView)
library(pwr)
library(lattice)
```

In this example, we will perform the `kruskal.test` function on a data frame from the native `stats` package. The example data is from Hollander & Wolfe (1973); it is measurements of the mucociliary efficiency in the rate of dust removal among normal subjects, subjects with obstructive airway disease, and subjects with asbestosis. 

We will work through a complete example with plots, post-hoc tests, and alternative methods for the example used in R help that you can access through RStudio by typing `?kruskall.wallis`.

#### Specify the order of the Factor Levels

The data is already in memory named `Data`. `dplyr` is already in the library, so let's mutate `Data$Health` so it is a factor variable that has no repeating levels.

```{r mutate, exercise=TRUE, eval = FALSE}
Data <- mutate(Data,
               Health = factor(Health, levels=unique(Health)))
```

#### Have a Look before Testing: Medians and Descriptive Statistics

Summarize `Efficiency` by `Health.`

```{r summarize, exercise=TRUE, eval = FALSE}
Summarize(Efficiency ~ Health,
          data = Data)
```

As you can see in the output, `Health` has three groups: Normal, OAD, and Asbestosis. For each group, `Summarize` shows the number in the group, the mean, the standard deviation, the minimum and maximum values, the mediam, and the interquartile points. 

Let's visualize the same data using the `lattice` plotting package's `histogram` function.

```{r viz, exercise=TRUE, eval = FALSE}
histogram(~ Efficiency | Health, 
          data=Data,
          layout=c(1,3))      #Number of columns and rows of individual plots
```

The result is stacked histograms for each group we might examine in a Kruskal–Wallis test.  If the distributions are similar, then the Kruskal–Wallis test will test for a difference in medians. In this case, each group's _n_ is very low, so the distributions are difficult to interpret.

Let's look at the same information using boxplots.

```{r boxplots, exercise=TRUE, eval = FALSE}
boxplot(Efficiency ~ Health,
        data = Data,
        ylab="Efficiency",
        xlab="Health")
```

#### Test the Hypothesis

Interpreting the null and alternative hypotheses for a typical Kruskal-Wallis test we arrive at these:

>H<sub>0</sub> is that the mean ranks are equal among Normal, OAD, and asbestosis health groups.    
H<sub>A</sub> is that mean ranks among the three groups are not equal.


```{r run_test, exercise=TRUE, eval = FALSE}
kruskal.test(Efficiency ~ Health, 
             data = Data)
```

The output shows that the mean ranks are not different. We fail to reject H<sub>0</sub>---nor do we accept it. This test, like so many hypothesis tests _proves_ nothing but that we cannot safely accept H<sub>A</sub>. 

#### What if _p_ had been < .05?

If the Kruskal–Wallis test were significant, we would have continued on to performa a post-hoc analysis to determine which levels of the independent variable differed from which other level.  

Heck, let's do it anyway. Many people use the Dunn test from the `dunnTest` function in the `FSA` package.  Adjustments to the _p_ values could be made using the `method` option to control the familywise error rate or to control the false discovery rate.  See `?p.adjust` for details.

Zar (2010) said that the Dunn test is appropriate for groups with unequal numbers of observations.

If there are several values to compare, it can be beneficial to have R convert this table to a compact letter display for you.  The `cldList` function in the `rcompanion` package can do this.

Here is the code for a Dunn test.

```{r dunn, exercise=TRUE, eval = FALSE}
### Order groups by median
Data$Health <- factor(Data$Health, 
                      levels=c("OAD", "Normal", "Asbestosis"))

### Run the Dunn test
PT = dunnTest(Efficiency ~ Health,
              data=Data,
              method="bh")    # Can adjust p-values; 
                              # See ?p.adjust for options 
## See the results
PT
```

Now to make the output pretty.

```{r make_it_pretty, exercise=TRUE, eval = FALSE}
PT <- PT$res
PT
cldList(comparison = PT$Comparison,
        p.value    = PT$P.adj,
        threshold  = 0.05)
```

Well, we didn't have significant differences, so there was nothing to see. Hence the error.

Let's try again with a different data set, the submissive dog data in McDonal's _Handbook_ on pages 161 and 162. The next code chunk populates the data and runs the test.

```{r prepare-dog, eval = FALSE}
Input =("
Dog          Sex      Rank
 Merlino      Male     1
 Gastone      Male     2
 Pippo        Male     3
 Leon         Male     4
 Golia        Male     5
 Lancillotto  Male     6
 Mamy         Female   7
 Nanà         Female   8
 Isotta       Female   9
 Diana        Female  10
 Simba        Male    11
 Pongo        Male    12
 Semola       Male    13
 Kimba        Male    14
 Morgana      Female  15
 Stella       Female  16
 Hansel       Male    17
 Cucciola     Male    18
 Mammolo      Male    19
 Dotto        Male    20
 Gongolo      Male    21
 Gretel       Female  22
 Brontolo     Female  23
 Eolo         Female  24
 Mag          Female  25
 Emy          Female  26
 Pisola       Female  27
 ")
Data = read.table(textConnection(Input),header=TRUE)
```
```{r dog, exercise = TRUE, exercise.setup = "prepare-dog", eval = FALSE}
kruskal.test(Rank ~ Sex, 
             data = Data)
```

That's more like it: a low _p_ value. Now create a boxplot to see how the groups differ.


```{r graph_dog, exercise=TRUE, exercise.setup = "prepare-dog", eval = FALSE}
boxplot(Rank ~ Sex,
        data = Data,
        ylab="Rank",
        xlab="Sex")
```

Female dogs have higher median rank than male dogs in this data set and most likely outside this data set as well (that's what a _p_ value means). 

Let's look at one final example---concerning oyster DNA.

```{r oysters, exercise=TRUE, eval = FALSE}
### --------------------------------------------------------------
### Kruskal–Wallis test, oyster DNA example, pp. 163–164
### --------------------------------------------------------------

Input =("
 Markername  Markertype  fst
 CVB1        DNA        -0.005
 CVB2m       DNA         0.116
 CVJ5        DNA        -0.006
 CVJ6        DNA         0.095
 CVL1        DNA         0.053
 CVL3        DNA         0.003
 6Pgd        protein    -0.005
 Aat-2       protein     0.016
 Acp-3       protein     0.041
 Adk-1       protein     0.016
 Ap-1        protein     0.066
 Est-1       protein     0.163
 Est-3       protein     0.004
 Lap-1       protein     0.049
 Lap-2       protein     0.006
 Mpi-2       protein     0.058
 Pgi         protein    -0.002
 Pgm-1       protein     0.015
 Pgm-2       protein     0.044
 Sdh         protein     0.024
")

Data = read.table(textConnection(Input),header=TRUE)
kruskal.test(fst ~ Markertype, 
             data = Data)
boxplot(fst ~ Markertype,
        data = Data,
        ylab="fst",
        xlab="Markertype")
```

The results are not significant, and the boxplot confirms the finding. The median ranks are very close. 

## References

John McDonald's [Handbook of Biostatistics](http://www.biostathandbook.com/kruskalwallis.html)

Salvatore S. Magnifiaco's [An R Companion for the Handbook of Biostatistics](https://rcompanion.org/rcompanion/a_02.html)